import requests
from bs4 import BeautifulSoup
import smtplib
from email.mime.text import MIMEText
from email.header import Header
import os
import datetime
import urllib3

# ç¦ç”¨å®‰å…¨è­¦å‘Šï¼ˆå­¦æ ¡ç½‘ç«™è¯ä¹¦ç»å¸¸è¿‡æœŸï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é…ç½®åŒºåŸŸ ---
SMTP_SERVER = "smtp.qq.com"
SMTP_PORT = 465
MAIL_USER = os.getenv("MAIL_USER")
MAIL_PASS = os.getenv("MAIL_PASS")
RECEIVER_EMAIL = os.getenv("MAIL_USER")

HISTORY_FILE = "history.txt"

# --- å®šä¹‰ç›®æ ‡ ---
SCHOOLS = [
    {
        "name": "åŠ›å·¥å­¦é™¢-é€šçŸ¥å…¬å‘Š",
        # åŠ›å·¥å­¦é™¢çš„ç½‘å€ä½ ä¹‹å‰å·²ç»è·‘é€šäº†ï¼Œä¿æŒä¸å˜
        "candidates": [
            "https://smes.shu.edu.cn/index/tzgg.htm",
            "https://smes.shu.edu.cn/tzgg.htm"
        ],
        "selectors": ["div[class*='list'] li a", ".winstyle67696 a", "ul li a"]
    },
    {
        "name": "ä¸Šå¤§ç ”ç©¶ç”Ÿé™¢-é€šçŸ¥å…¬å‘Š",
        # âœ… è¿™é‡Œä¿®å¤äº†ï¼åˆ©ç”¨ä½ æä¾›çš„çº¿ç´¢ 1027
        "candidates": [
            "https://gs.shu.edu.cn/index/1027.htm",  # å¯èƒ½æ€§1ï¼šæ•°å­—IDç´¢å¼• (æœ€å¯èƒ½)
            "https://gs.shu.edu.cn/tzgg.htm"         # å¯èƒ½æ€§2ï¼šå¤‡ç”¨
        ],
        # é€‰æ‹©å™¨ä¿æŒå®½æ³›ï¼Œåªè¦æ˜¯åˆ—è¡¨é‡Œçš„é“¾æ¥éƒ½æŠ“
        "selectors": ["div[class*='list'] li a", ".winstyle196036 a", "ul li a", "table.winstyle126615 a"]
    }
]

def send_email(title, link, source_name):
    if not MAIL_USER or not MAIL_PASS:
        return
    try:
        subject = f"ã€æ–°é€šçŸ¥ã€‘{source_name}: {title}"
        content = f"æ¥æº: {source_name}\næ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\næ ‡é¢˜: {title}\né“¾æ¥: {link}"
        
        message = MIMEText(content, 'plain', 'utf-8')
        message['From'] = MAIL_USER
        message['To'] = RECEIVER_EMAIL
        message['Subject'] = Header(subject, 'utf-8')

        server = smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT)
        server.login(MAIL_USER, MAIL_PASS)
        server.sendmail(MAIL_USER, [RECEIVER_EMAIL], message.as_string())
        server.quit()
        print(f"ğŸ“§ é‚®ä»¶å·²å‘é€: {title}")
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

def run_task():
    print(f"[{datetime.datetime.now()}] å¼€å§‹æŠ“å–...")
    
    # ä¼ªè£…æˆæµè§ˆå™¨
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    # è¯»å–å†å²
    history = set()
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            for line in f:
                history.add(line.strip())
    
    new_history = history.copy()
    has_new = False

    for school in SCHOOLS:
        print(f"\næ­£åœ¨å°è¯•è¿æ¥: {school['name']}")
        valid_soup = None
        used_url = ""

        # === 1. å¯»æ‰¾æ­£ç¡®çš„ç½‘å€ ===
        for url in school['candidates']:
            try:
                print(f"  Trying: {url} ...", end="")
                # verify=False å¿½ç•¥è¯ä¹¦é”™è¯¯
                resp = requests.get(url, headers=headers, timeout=15, verify=False)
                resp.encoding = 'utf-8'
                
                if resp.status_code == 200:
                    # ç®€å•æ£€æŸ¥ä¸€ä¸‹é¡µé¢æœ‰æ²¡æœ‰å†…å®¹ï¼Œé˜²æ­¢å‡æ­»
                    if len(resp.text) > 500:
                        print(" âœ… é€šäº†ï¼")
                        valid_soup = BeautifulSoup(resp.text, 'html.parser')
                        used_url = url
                        break
                    else:
                        print(" âš ï¸ å†…å®¹è¿‡çŸ­(å¯èƒ½è¢«å±è”½)")
                else:
                    print(f" âŒ {resp.status_code}")
            except Exception as e:
                print(f" âŒ å‡ºé”™")
        
        if not valid_soup:
            print(f"âš ï¸ {school['name']} æ— æ³•è®¿é—®ï¼Œè·³è¿‡ã€‚")
            continue

        # === 2. æŠ“å–å†…å®¹ ===
        links = []
        for selector in school['selectors']:
            found = valid_soup.select(selector)
            if found:
                links = found
                break
        
        found_count = 0
        for link in links:
            href = link.get('href')
            title = link.get_text(strip=True)
            
            # è¿‡æ»¤æ— æ•ˆæ ‡é¢˜
            if not href or len(title) < 4 or "æ›´å¤š" in title: continue
            
            # æ‹¼æ¥é“¾æ¥
            if not href.startswith("http"):
                if href.startswith("/"):
                    # ç»å¯¹è·¯å¾„ /info/...
                    domain = "/".join(used_url.split("/")[:3])
                    full_url = domain + href
                else:
                    # ç›¸å¯¹è·¯å¾„ info/... æˆ– ../info/...
                    # ç®€å•å¤„ç†ï¼šå¦‚æœæ˜¯ info/ å¼€å¤´ï¼Œç›´æ¥æ‹¼åŸŸå
                    if href.startswith("info/"):
                         domain = "/".join(used_url.split("/")[:3])
                         full_url = f"{domain}/{href}"
                    else:
                         full_url = used_url.rsplit("/", 1)[0] + "/" + href
            else:
                full_url = href

            found_count += 1
            
            # === æ ¸å¿ƒé€»è¾‘ ===
            if full_url not in history:
                new_history.add(full_url)
                has_new = True
                
                # âœ… è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼š
                # å¦‚æœå†å²è®°å½•ä¸æ˜¯ç©ºçš„ï¼ˆè¯´æ˜ä¸æ˜¯ç¬¬ä¸€æ¬¡è·‘ï¼‰ï¼Œå°±å‘é‚®ä»¶
                # å¦‚æœä½ æƒ³ç«‹åˆ»æµ‹è¯•ç ”ç©¶ç”Ÿé™¢çš„é‚®ä»¶ï¼Œå¯ä»¥æš‚æ—¶æŠŠ "and len(history) > 0" åˆ æ‰
                if len(history) > 0:
                    send_email(title, full_url, school['name'])
                else:
                    print(f"  [åˆå§‹åŒ–æ”¶å½•] {title}")

        print(f"  > è§£æå‡º {found_count} æ¡é€šçŸ¥")

    # ä¿å­˜
    if has_new:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            for url in sorted(list(new_history)):
                f.write(url + "\n")
        print("\nâœ… å†å²è®°å½•å·²æ›´æ–°")
    else:
        print("\næš‚æ— æ–°å†…å®¹")

if __name__ == "__main__":
    run_task()
