import requests
from bs4 import BeautifulSoup
import smtplib
from email.mime.text import MIMEText
from email.header import Header
import os
import datetime
import urllib3
import time  # <--- å¼•å…¥æ—¶é—´åº“ï¼Œç”¨æ¥"ä¼‘æ¯"

# å¿½ç•¥è¯ä¹¦è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é…ç½®åŒºåŸŸ ---
SMTP_SERVER = "smtp.qq.com"
SMTP_PORT = 465
MAIL_USER = os.getenv("MAIL_USER")
MAIL_PASS = os.getenv("MAIL_PASS")
RECEIVER_EMAIL = os.getenv("MAIL_USER")

HISTORY_FILE = "history.txt"

SCHOOLS = [
    {
        "name": "åŠ›å·¥å­¦é™¢-é€šçŸ¥å…¬å‘Š",
        "urls": ["https://smes.shu.edu.cn/index/tzgg.htm"],
        "selectors": ["div[class*='list'] li a", ".winstyle67696 a", "ul li a"]
    },
    {
        "name": "ä¸Šå¤§ç ”ç©¶ç”Ÿé™¢-ç»¼åˆé€šçŸ¥",
        "urls": [
            # ä¼˜å…ˆå°è¯•æ–°é—»ä¸­å¿ƒä¸»é¡µï¼ˆè¿™é‡Œé€šå¸¸åŒ…å«æœ€æ–°é€šçŸ¥ï¼‰
            "https://gs.shu.edu.cn/xwzx.htm",
            "https://gs.shu.edu.cn/index.htm"
        ],
        # åªè¦é“¾æ¥åŒ…å« info/1027 (å…¬å‘ŠID) æˆ– info/1029 (åŸ¹å…»ID) å°±æŠ“å–
        "keywords": ["info/1027", "info/1029"],
        "selectors": ["a"] 
    }
]

def send_email(title, link, source_name):
    if not MAIL_USER or not MAIL_PASS:
        return
    try:
        subject = f"ã€æ–°é€šçŸ¥ã€‘{source_name}: {title}"
        content = f"æ¥æº: {source_name}\næ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\næ ‡é¢˜: {title}\né“¾æ¥: {link}"
        
        message = MIMEText(content, 'plain', 'utf-8')
        message['From'] = MAIL_USER
        message['To'] = RECEIVER_EMAIL
        message['Subject'] = Header(subject, 'utf-8')

        server = smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT)
        server.login(MAIL_USER, MAIL_PASS)
        server.sendmail(MAIL_USER, [RECEIVER_EMAIL], message.as_string())
        server.quit()
        print(f"ğŸ“§ é‚®ä»¶å·²å‘é€: {title}")
        
        # === å…³é”®ä¿®æ”¹ï¼šæ¯å‘ä¸€å°ä¿¡ï¼Œä¼‘æ¯ 5 ç§’ ===
        print("   (ä¼‘æ¯5ç§’é˜²æ­¢è¢«å°)...")
        time.sleep(5) 
        
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

def run_task():
    print(f"[{datetime.datetime.now()}] å¼€å§‹æŠ“å–...")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    history = set()
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            for line in f:
                history.add(line.strip())
    
    new_history = history.copy()
    has_new = False

    for school in SCHOOLS:
        print(f"\næ­£åœ¨è¿æ¥: {school['name']}")
        soup = None
        used_url = ""

        for url in school['urls']:
            try:
                print(f"  Trying: {url} ...", end="")
                resp = requests.get(url, headers=headers, timeout=15, verify=False)
                resp.encoding = 'utf-8'
                if resp.status_code == 200 and len(resp.text) > 500:
                    print(" âœ… é€šäº†")
                    soup = BeautifulSoup(resp.text, 'html.parser')
                    used_url = url
                    break
                else:
                    print(f" âŒ {resp.status_code}")
            except:
                print(" âŒ è¶…æ—¶")
        
        if not soup:
            continue

        # æŠ“å–é“¾æ¥
        found_links = []
        
        # ç­–ç•¥A: å…³é”®å­—è¿‡æ»¤ (é’ˆå¯¹ç ”ç©¶ç”Ÿé™¢)
        if "keywords" in school:
            all_a = soup.find_all('a')
            for a in all_a:
                href = a.get('href')
                if href:
                    # åªè¦åŒ…å«ä»»æ„ä¸€ä¸ªå…³é”®å­—
                    if any(k in href for k in school['keywords']):
                        found_links.append(a)
        
        # ç­–ç•¥B: é€‰æ‹©å™¨ (é’ˆå¯¹åŠ›å·¥å­¦é™¢)
        else:
            for sel in school['selectors']:
                found_links = soup.select(sel)
                if found_links: break

        print(f"    > æ‰¾åˆ° {len(found_links)} ä¸ªç›¸å…³é“¾æ¥")

        for link in found_links:
            href = link.get('href')
            title = link.get_text(strip=True)
            
            if not href or len(title) < 4: continue
            
            # è¡¥å…¨é“¾æ¥
            if not href.startswith("http"):
                if href.startswith("/"):
                    domain = "/".join(used_url.split("/")[:3])
                    full_url = domain + href
                else:
                    if href.startswith("info/"): # ä¿®å¤ç›¸å¯¹è·¯å¾„
                         domain = "/".join(used_url.split("/")[:3])
                         full_url = f"{domain}/{href}"
                    else:
                         full_url = used_url.rsplit("/", 1)[0] + "/" + href
            else:
                full_url = href

            if full_url not in history:
                new_history.add(full_url)
                has_new = True
                
                # å‘é€é‚®ä»¶ (åªè¦å†å²è®°å½•ä¸ä¸ºç©ºå°±å‘)
                if len(history) > 0:
                    send_email(title, full_url, school['name'])
                else:
                    print(f"    [åˆå§‹åŒ–] {title}")

    # ä¿å­˜
    if has_new:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            for url in sorted(list(new_history)):
                f.write(url + "\n")
        print("\nâœ… è®°å½•å·²æ›´æ–°")

if __name__ == "__main__":
    run_task()
